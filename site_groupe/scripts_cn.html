<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">

  <title>Script | CN</title>

  <meta content="Cuixiaohua_version 12" name="keywords">
  <link href="assets/img/favicon.png" rel="icon">
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Nunito:300,300i,400,400i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/css/style.css" rel="stylesheet">


  <!--  CSS et Js Files pour scripts -->
  <link rel="stylesheet" href="assets/css/monokai-sublime.min.css">
  <script src="assets/js/highlight.min.js"></script>
  <script>
    hljs.initHighlightingOnLoad();
</script>

</head>

<body>

  <!-- ======= Header ======= -->
  <header class="header fixed-top bg-dark">
    <div class="container-fluid d-flex align-items-center justify-content-between">
      <a class="logo">
        <img src="site_groupe/assets/img/groupeicon.jpeg">
        <span>Projet Encadré</span>
      </a>
      <nav id="navbar" class="navbar bg-dark">
        <ul>
          <li><a class="nav-link scrollto" href="../index.html">Accueil</a></li>   <!-- ======= avec presentation ======= -->
          <li><a class="nav-link scrollto" href="../index.html#presentation">Présentation</a></li>
          <li class="dropdown"><a href="#"><span>Tableaux</span> <i class="bi bi-chevron-down"></i></a>
            <ul>
              <li><a href="tableaux-cn.html">Tableau - CN</a></li>
              <li><a href="Tableaux-FR.html">Tableau - FR</a></li>
              <li><a href="Tableaux-EN.html">Tableau - EN</a></li>
            </ul>
          </li>
          <li class="dropdown"><a href="#"><span class="active">Scripts</span> <i class="bi bi-chevron-down"></i></a>
            <ul>
              <li class="active"><a href="scripts_cn.html" class= "active">Script - CN</a></li>
              <li><a href="scripts_fr.html">Script - EN | FR</a></li>
            </ul>
          </li>
          <li class="dropdown"><a href="#"><span>iTrameur&Nuages</span> <i class="bi bi-chevron-down"></i></a>
            <ul>
              <li><a href="itrameur_nuages.html">Chinois</a></li>
              <li><a href="">Français</a></li>
              <li><a href="">English</a></li>
            </ul>
          </li>
          <li><a class="nav-link" href="propos.html">Nous</a></li>
          <li><a href="blog.html">Blog</a></li>
          <a href="https://github.com/gemmafelton/PPE-group" class="github"><i class="bi bi-github" style="font-size: 40px;"></i></a>
          </ul>
      </nav><!-- .navbar -->

    </div>
  </header>






  
<main id="main">
<section class="modul">
<div class="bg-image h-100" style="margin-bottom: -60px ; background-image: url('https://w.wallhaven.cc/full/85/wallhaven-85ok3o.png');">
<div class="mask align-items-center h-100" style="background-color: rgba(0, 0, 0, 0.25); "> 
  
  <section>
  <header class="section-header">
    <h2>&nbsp&nbsp&nbsp&nbsp&nbsp脚本</h2>
    <p style="color:rgb(255, 255, 255) ;">Les Scripts Chinois</p>
    <h5 style="margin-top: 50px; color:rgb(241, 240, 240) ;">Ces divers scripts en dessous sont crées et utilisés au fur et à mesure que le projet avançait.   </p>
  </header>
  </section>

  <div class="container">
    <div class="row justify-content-center">
      <div class="col-12">
        <div class="card bg-dark">
          <div class="row motifs-tabs">          
            <div class="forwhat1 col-lg-4" style="margin: 0 0 20px 50px ; color: rgb(154, 241, 13);">
              <h3>Script créant les fichiers du corpus </h3>
              <p style="color:azure; text-align: justify;"><strong>dumps_asp_conc_cont_ch.sh</strong>, basé sur les scripts montrés par les professeurs, est crée et combiné par Xiaohua. C'est le script  pour créer le corpus de notre analyse.</p>
              <p style="color:azure; text-align: justify;">Avec ce script, le seul argument attendu est le fichier urls.
                On peut ainsi créer les fichiers dumps-text, aspirations, contextes, cooccurences et les mettre dans le dossier correspondant. </p>
                <p style="color:azure ; text-align: justify;">La base de notre analyse est ainsi construite.</p>
              <br>
              <p>
              <a href="https://github.com/Simounawind/PPE1/blob/main/projet_final/scripts/dumps_asp_conc_cont_ch.sh" class="github"><i class="bi bi-github" style="font-size: 40px;"></i></a>
              &ensp;&ensp;&ensp;
              <a href="https://github.com/Simounawind/PPE1/blob/main/projet_final/scripts/dumps_asp_conc_cont_ch.sh" download="dumps_asp_conc_cont_ch.sh" class="download"><i class="bi bi-download" style="font-size: 40px;"></i></a>
  
            </p>
            </div>

          <div class="col-lg-6">
          <pre class='script Bash' ><code>
#!/usr/bin/env bash
fichier_urls=$1 # le fichier d'URL en entrée
lignenum=1;
cible="种族歧视"
while read URL || [[ -n $URL ]];
do
  echo "fichier $lignenum est en cours de traitement."
  curl -o ../../aspirations/chinois/ch-$lignenum.html $URL
  w3m $URL &gt; ../../dumps-text/chinois/ch-$lignenum.txt
  grep -E -A3 -B3 $cible ../../dumps-text/chinois/ch-$lignenum.txt &gt; ../../contexte/chinois/ch-$lignenum.txt

  echo "
  &lt;!DOCTYPE html&gt;
  &lt;html&gt;
  &lt;head&gt;
    &lt;meta charset="utf-8"&gt;
    &lt;meta name="viewport" content="width=device-width, initial-scale=1"&gt;
    &lt;title&gt;Concordances&lt;/title&gt;
    &lt;link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css"&gt;
  &lt;/head&gt;
      &lt;body&gt;
        &lt;table class="table"&gt;
          &lt;thead&gt;
            &lt;tr&gt;
            &lt;th class=\"has-text-right\"&gt;Contexte gauche&lt;/th&gt;
            &lt;th&gt;Cible&lt;/th&gt;
            &lt;th class=\"has-text-left\"&gt;Contexte droit&lt;/th&gt;
            &lt;/tr&gt;
          &lt;/thead&gt;
          &lt;tbody&gt;
  " &gt; ../../concordances/chinois/concordance_ch-$lignenum.html
  w3m -cookie $URL | grep -E -o "(\w+|\W+){0,10}$cible(\W+|\w+){0,10}" |sort|uniq | sed -E "s/(.*)($cible)(.*)/&lt;tr&gt;&lt;td class="has-text-right"&gt;\1&lt;\/td&gt;&lt;td class="has-text-centered"&gt;&lt;strong&gt;\2&lt;\/strong&gt;&lt;\/td&gt;&lt;td class="has-text-left"&gt;\3&lt;\/td&gt;&lt;\/tr&gt;/" &gt;&gt; ../../concordances/chinois/concordance_ch-$lignenum.html
  echo "
  &lt;/tbody&gt;
  &lt;/table&gt;
  &lt;/body&gt;
  &lt;/html&gt;
  " &gt;&gt; ../../concordances/chinois/concordance_ch-$lignenum.html
  lignenum=$((lignenum+1));
done &lt; $fichier_urls
exit                       
                </code></pre></div>
              </div>
              <br><br><br>
              <hr class="hr-edge-weak">

    <!-- ======= script-2 ======= -->   

              <div class="row motifs-tabs">          
                <div class="forwhat2 col-lg-4" style="margin: 0 0 20px 50px ; color: rgb(154, 241, 13);">
                  <h3>Script créant le tableau </h3>
                  <p style="color:azure; text-align: justify;">C'est le script pour créer le tableau.</p>
                  <p style="color:azure; text-align: justify;">Avec ce script, on obtiendra des infos utiles concernant les urls, leur contenu, y compris les occurrences du mot cible, ses concordances, son contexte etc... </p>
                    <p style="color:azure ; text-align: justify;">la commande <i style="color:rgb(22, 227, 90);">curl</i> correspande aux fichiers aspirés, <i style="color:rgb(239, 184, 18);">lynx</i> aux dumps-texts, et <i style="color:rgb(13, 159, 243);">w3m</i> pour obtenir les dumps-texts chinois. On a aussi utilisé fréquemment le <i style="color:rgb(232, 4, 4);">tube</i> de linux pour transporter les contenus.</p>
                    <p style="color:azure ; text-align: justify;">Enfin, on affichera tout ce qu'on a obtenu dans le tableau de style très simple, qui contient 9 colonnes et ainsi ceux qu'on a obtenu par ce script</p>
                  <br>
                  <p>
                  <a href="https://github.com/Simounawind/PPE1/blob/main/projet_final/scripts/base_tableaux_fichier_ch.sh" class="github"><i class="bi bi-github" style="font-size: 40px;"></i></a>
                  &ensp;&ensp;&ensp;
                  <a href="https://github.com/Simounawind/PPE1/blob/main/projet_final/scripts/base_tableaux_fichier_ch.sh" class="download"><i class="bi bi-download" style="font-size: 40px;"></i></a>
                  </p>
                </div>
                
              <div class="col-lg-6">
              <pre class='script Bash' ><code>
#!/usr/bin/env bash

fichier_urls=$1 # le fichier d'URL en entrée
fichier_tableau=$2 # le fichier HTML en sortie

if [[ $# -ne 2 ]]
then
  echo "Ce programme demande exactement deux arguments."
  exit
fi

mot="种族歧视" # 关键词

echo $fichier_urls;
basename=$(basename -s .txt $fichier_urls)

echo "
  &lt;html&gt;
  &lt;body&gt;" &gt; $fichier_tableau
echo "&lt;h2&gt;Tableau $basename :&lt;/h2&gt;" &gt;&gt; $fichier_tableau
echo "&lt;br&gt;&lt;/br&gt;" &gt;&gt; $fichier_tableau
echo "&lt;table&gt;" &gt;&gt; $fichier_tableau
echo "&lt;tr&gt;
  &lt;th&gt;ligne&lt;/th&gt;
  &lt;th&gt;code&lt;/th&gt;
  &lt;th&gt;URL&lt;/th&gt;
  &lt;th&gt;Encodage&lt;/th&gt;
  &lt;th&gt;Occurences&lt;/th&gt;
  &lt;th&gt;DumpText&lt;/th&gt;
  &lt;th&gt;HTML&lt;/th&gt;
  &lt;th&gt;Contexte&lt;/th&gt;
  &lt;th&gt;Concordances&lt;/th&gt;
  &lt;/tr&gt;" &gt;&gt; $fichier_tableau

lignenum=1;
while read -r URL || [[ -n ${URL} ]]; do

  # la façon attendue, sans l'option -w de cURL
  code=$(curl -ILs $URL | grep -e "^HTTP/" | grep -Eo "[0-9]{3}" | tail -n 1)
  charset=$(curl -Ls $URL | grep -Eo "charset=(\w|-)+" |tail | cut -d= -f2 |tail -n 1)
  Occurences=$(w3m -cookie $URL | egrep "种族歧视" -wc)
  echo -e "\tURL : $URL";
  echo -e "\tcode : $code";

  if [[ ! $charset ]]
  then
    echo -e "\tencodage non détecté, on prendra UTF-8 par défaut.";
    charset="UTF-8";
  else
    echo -e "\tencodage : $charset";
  fi

  if [[ $code -eq 200 ]]
  then
    dump=$(lynx -dump -nolist -assume_charset=$charset -display_charset=$charset $URL)
    if [[ $charset -ne "UTF-8" && -n "$dump" ]] #command1 && command2  只有前面命令执行成功，后面命令才继续执行    -n  表示if [ -n str1 ]　　　　　　 当串的长度大于0时为真(串非空) 
    then
      dump=$(echo $dump | iconv -f $charset -t UTF-8//IGNORE)  #也就是说，如果检查出其编码信息不为空，且不等于utf8时，就要把它转成utf8
    fi
  else
    echo -e "\tcode différent de 200 utilisation d'un dump vide"
    dump=""
    charset=""
  fi

  echo "&lt;tr&gt;
  &lt;td&gt;$lignenum&lt;/td&gt;
  &lt;td&gt;$code&lt;/td&gt;
  &lt;td&gt;&lt;a href=\"$URL\"&gt;$URL&lt;/a&gt;&lt;/td&gt;
  &lt;td&gt;$charset&lt;/td&gt;&lt;td&gt;$Occurences&lt;/td&gt;
  &lt;td&gt;&lt;a href=\"../dumps-text/ch-$lignenum.txt\"&gt;text&lt;/a&gt;&lt;/td&gt;
  &lt;td&gt;&lt;a href=\"../aspirations/ch-$lignenum.html\"&gt;html&lt;/a&gt;&lt;/td&gt;
  &lt;td&gt;&lt;a href=\"../contextes/ch-$lignenum.txt\"&gt;contexte&lt;/a&gt;&lt;/td&gt;
  &lt;td&gt;&lt;a href=\"../concordances/concordance_ch-$lignenum.html\"&gt;concordance&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;" &gt;&gt; $fichier_tableau
  echo -e "\t----------------------------------------------------------------"
  lignenum=$((lignenum+1));
done &lt; $fichier_urls
echo "&lt;/table&gt;" &gt;&gt; $fichier_tableau
echo "&lt;/body&gt;&lt;/html&gt;" &gt;&gt; $fichier_tableau
                    </code></pre></div>
                  </div>



                  <br><br><br>
                  <hr class="hr-edge-weak">





                  
    <!-- ======= script-3 script shell for itrameur ======= -->   

    <div class="row motifs-tabs">          
      <div class="forwhat1 col-lg-4" style="margin: 0 0 20px 50px ; color: rgb(154, 241, 13);">
        <h3>Script concaténant les dumps text</h3>
        <p style="color:azure; text-align: justify;">Après avoir obtenu tant de fichier text, il faut les concaténer dans un seul fichier, tout en insérant les délimiteurs comme &lt;page="ch-24"&gt.</p>
        <p style="color:azure; text-align: justify;">Il suffit d'employer des connaissances de bash et de shell qu'on a appris en cours pour réaliser cela.</p>

            <br>
        <p>
        <a href="https://github.com/Simounawind/PPE1/blob/main/projet_final/itrameur/make_itrameur_corpus.sh" class="github"><i class="bi bi-github" style="font-size: 40px;"></i></a>
        &ensp;&ensp;&ensp;
        <a href="https://github.com/Simounawind/PPE1/blob/main/projet_final/itrameur/make_itrameur_corpus.sh" class="download"><i class="bi bi-download" style="font-size: 40px;"></i></a>
        </p>
      </div>
      <div class="col-lg-6">
        <pre class='script python' ><code>
#!/usr/bin/zsh

if  [[ $# -ne 2 ]]
then 
echo "Deux arguments attendus: &lt;dossier&gt; &lt;langue&gt;"
exit
fi

dossier=$1
langue_abr=$2   

echo "&lt;lang=\"$langue_abr\"&gt;" &gt; contexte.txt


for filepath in $(ls -Utr $dossier/$langue_abr-*.txt)
do
# filepath == dumps-text/fr-1.txt
#  == &gt; pagename =fr-1
echo "$filepath"
pagename="$(basename -s .txt $filepath)"  #ch-1
echo "&lt;page=\"$pagename\"&gt;" &gt;&gt; contexte.txt
echo "&lt;text&gt;"  &gt;&gt; contexte.txt

#on récupère les dumps ou contextes
# et on écrit à l'intérieur de la base text
content=$(cat $filepath)
# ordre important : & en premier
# sinon : &lt; =&gt; &lt ; =&gt; &amp;lt: 
content=$(echo "$content" | sed 's/&/&amp;/g')
content=$(echo "$content" | sed 's/&lt;/&lt;/g')
content=$(echo "$content" | sed 's/&gt;/&gt;/g')  
echo "$content" &gt;&gt; contexte.txt
echo "&lt;/text&gt;" &gt;&gt; contexte.txt
echo "&lt;/page&gt; §" &gt;&gt; contexte.txt
done
echo "&lt;/lang&gt;" &gt;&gt; contexte.txt
              </code></pre></div>
            </div>

            <br><br><br>
            <hr class="hr-edge-weak">

   
    <!-- ======= script-4 jieba for itrameur ======= -->   

                  <div class="row motifs-tabs">          
                    <div class="forwhat1 col-lg-4" style="margin: -310px 0 20px 50px ; color: rgb(154, 241, 13);">
                      <h3>Script créant le corpus iTrameur</h3>
                          <p style="color:azure; text-align: justify;">C'est le script le plus difficile pour moi. Je l'utilisais pour créer le fichier txt avec des mots segmentés et pertinents. </p>
                          <p style="color:azure; text-align: justify;">Basé sur le "contexte.txt" déjà crée, il faut aussi segmenter son contenu parce qu'il n'y a pas de space entre chaque mots chinois dans une phrase. Donc j'ai utilisé <i style="color:rgb(93, 93, 233)">jieba</i>, qui est un set de fonctions qui nous permet de segmenter les textes en chinois. J'ai utilisé le mode normal pour ne pas créer des mots redondants.</p>
                          <p style="color:azure; text-align: justify;">Mais là j'ai eu un problème que je n'arrivais toujours pas à résoudre. Avec jieba, on segmente aussi les délimiteurs. Avec <i style="color:coral">jieba.load_userdict('userdict.txt')</i> je n'arrive pas non plus à garder les délimiteurs, parce que jieba n'accepte pas les crochets pointus, j'ai donc cherché sur Internet et j'ai modifié les codes source de jieba, enfin les délimiteurs sont gardés. Mais les stopwords existent encore !!! Donc j'ai dû corriger manuellement les délimiteurs. Heureusement cela ne m'a pas coûté pas beaucoup de temps.
                             Mais grâce à ce script, les contenus dans context.txt sont annotés avec les délimiteurs suggérés dans le site officiel d'iTrameur, et le contenu est assez nettoyé.</p>
                             <p style="color:azure; text-align: justify;"> Nous pouvons ainsi utiliser le fichier sans délimiteurs pour la création des nuages de mots. ☁️</p>
                          <br>
                      <p>
                      <a href="https://github.com/Simounawind/PPE1/blob/main/projet_final/itrameur/jieba_itrameur.py" class="github"><i class="bi bi-github" style="font-size: 40px;"></i></a>
                      &ensp;&ensp;&ensp;
                      <a href="https://github.com/Simounawind/PPE1/blob/main/projet_final/itrameur/jieba_itrameur.py" class="download"><i class="bi bi-download" style="font-size: 40px;"></i></a>
                      </p>
                    </div>
                  <div class="col-lg-6">
                  <pre class='script Python' ><code>

import jieba

#jieba.load_userdict('userdict.txt') mais marche pas
def stopwordslist(filepath):
    stopwords = [line.strip() for line in open(filepath, 'r', encoding='utf-8').readlines()]
    return stopwords

# pour segmenter
def seg_sentence(sentence):
    sentence_seged = jieba.cut(sentence.strip())
    stopwords = stopwordslist('stop_words.txt')
    outstr = ''
    for word in sentence_seged:
        if word not in stopwords:
            if word != '\t':
                outstr += word
                outstr += " "
    return outstr

# enfin
inputs = open('dumps.txt', 'r', encoding='utf-8')
outputs = open('corpus-ch_itrameur_final.txt', 'w')
for line in inputs:
    line_seg = seg_sentence(line)
    outputs.write(line_seg + '\n')
outputs.close()
inputs.close()                    
                        </code></pre></div>
                      </div>

                      <br><br><br><br><br><br><br><br>
                      <hr class="hr-edge-weak">

    <!-- ======= script-4 itrameurbonformat======= -->   

                      <div class="row motifs-tabs">          
                        <div class="forwhat1 col-lg-4" style="margin: 0 0 20px 50px ; color: rgb(154, 241, 13);">
                          <h3>Script - Nuages des mots ☁️</h3>
                          <p style="color:azure; text-align: justify;">C'est le script qui segmente les mots chinois, et ensuite crée l'image nuage de mots.</p>
                      <p style="color:azure; text-align: justify;">Toujour avec jieba, nous pouvons créer le nuage des mots avec wordcloud. Ayant maitrîsé les commandes de base de wordcloud, j'ai imité les codes d'autrui pour ajouter des couleurs et le beau font stylé.</p>
                        <p style="color:azure ; text-align: justify;">J'ai aussi créé un set de STOPWORDS ⛔️, qui contient tous les mots ou lettres qu'on ne veut pas afficher dans l'image.</p>
                         <br>
                         
                          <p>
                          <a href="https://github.com/Simounawind/PPE1/blob/main/projet_final/wordcloud/jieba_token_wordcloud.py" class="github"><i class="bi bi-github" style="font-size: 40px;"></i></a>
                          &ensp;&ensp;&ensp;
                          <a href="https://github.com/Simounawind/PPE1/blob/main/projet_final/wordcloud/jieba_token_wordcloud.py" class="download"><i class="bi bi-download" style="font-size: 40px;"></i></a>
                          </p>
                        </div>
                        <div class="col-lg-6">
                          <pre class='script Python' ><code>
        
import jieba
import matplotlib.pyplot as plt
from imageio import imread
from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator
import numpy as np
from PIL import Image


text_from_file = open('dumps.txt', 'r', encoding='UTF-8')
data = text_from_file.read()
seg_list = jieba.cut(data, cut_all=False)
# open & read file for tokenization -> tokenize line by line

fW = open('dumps-ch_token.txt', 'w', encoding='UTF-8')
word_space = ' '.join(seg_list)
fW.write(word_space)
# put result in new file, separate tokens by space

text_from_file.close()
fW.close()

STOPWORDS = set((
    "En", "ch", "text", "ais", "svg", "Fran", "text", "page", "text page", "b", "v2",
    "他", "看", "就", "以及", "其", "吗", "进行", "是", "用", "也", "的",
    "年", "了", "日", "月", "年", "都", "有", "你", "和", "我", "但", "而", "中", "不", "上", "这", "在", "到", "为", "与", "说", "对", "但是", "从", "会", "还", "将", "很", "让 ", " 让", "或", "等", "要", "来", "就是", "一种", "时", "并", "她", "表示", "一些", "这个", "又", "后", "以为", "以", "让",
    "通过", "者", "不是", "分享", "比", "里", "去", "所以", "向", "那", "那么", "广告", "或者", "应该", "一定", "一", "则", "I", "and", "已", "己", "什么", "才", "过", "设计", "因", "着因",
    "of", "the", "文章", "to", "认为", "时候", "它", "其中", "着", "方面", "所有", "没有", "之后", "已经", "前", "给", "这是", "这样", "开始", "一样", "指出", "该", "地", "这些", "需要", "曾", "现在", "地方", "好", "由", "像", "这是", "给", "特别", "作为", "当", "甚至", "个", "下", "最后", "包括", "如果", "发生", "最", "还是", "可以", "把", "时间", "不能", "却", "成为", "继续", "跟", "对于", "高", "当"
    "其实", "们", "来自", "一个", "可能", "觉得", "这种", "比如", "因为", "相关", "因此", "看到", "只是", "有关", "最近", "一直", "万", "一名", "仍", "及", "再", "您", "多", "导致", "想", "所", "非常", "Espa", "不要", "无法", "情况", "地位", "ol", "为了", "如何", "其他", "那些", "虽然", "为什么", "为了", "有人", "这一", "出", "一位", "很多", "主要", "", "",
))

img = imread('poing.png')
img = np.array(Image.open('poing.png'))

my_wordcloud = WordCloud(
    scale=6,
    background_color='white',  # 设置背景颜色
    mask=img,  # 背景图片
    max_words=200,  # 设置最大显示的词数
    stopwords=STOPWORDS,  # 设置停用词
    # 设置字体格式，字体格式 .ttf文件需自己网上下载，最好将名字改为英文，中文名路径加载会出现问题。
    font_path='alima.ttf',
    max_font_size=150,  # 设置字体最大值
    random_state=50,  # 设置随机生成状态，即多少种配色方案
).generate(word_space)

image_colors = ImageColorGenerator(img)
my_wordcloud.recolor(color_func=image_colors)
plt.imshow(my_wordcloud)
plt.axis('off')
plt.show()
my_wordcloud.to_file('result.jpg')
              </code></pre></div>
                              </div>
        
                              <br><br><br><br>
        <hr class="hr-edge-weak">

    <!-- ======= les sites tres utiles ======= -->   

                          <div class="row motifs-tabs">          
                            <div class="forwhat4 col-lg-4" style="margin: 0 0 20px 50px ; color: rgb(154, 241, 13);">
                              <h3>🌏 Sites utiles et Bibliographie</h3>
                              <p style="color:azure; text-align: justify;">Concernant les connaissances CSS, html etc</p>
                              <br>
                            </div>
                            
                          <div class="col-lg-6">
                          <pre class='scriptfinal txt' ><code>
https://developer.mozilla.org/en-US/docs/Web/CSS
https://blog.51cto.com/mouday/4838897
https://getbootstrap.com/
https://highlightjs.org/
https://github.com/highlightjs/highlight.js
https://www.jianshu.com/p/e2f12268fe81
https://www.v2ex.com/t/186829
https://getbootstrap.com/docs/5.3/getting-started/
                                </code></pre></div>
                        

        <br><br><br>
        <hr class="hr-edge-weak">
    <!-- ======= les sites d'images cités ======= -->   

    <div class="row motifs-tabs">          
      <div class="forwhat4 col-lg-4" style="margin: 0 0 20px 50px ; color: rgb(154, 241, 13);">
        <h3 id="sourceimage"> 📷 D'où viennent les images </h3>
        <p style="color:azure; text-align: justify;">merciiiiii</p>
        <br>
      </div>
      
    <div class="col-lg-6">
    <pre class='scriptfinal txt' ><code>
https://www.licra.org/loi-contre-le-racisme-anti-asiatique-aux-etats-unis
https://actualitte.com/article/101971/international/etats-unis-la-theorie-critique-de-la-race-se-heurte-a-la-censure
https://www.crisconsortium.org/challenging-racisms/mapping-anti-racism
https://unsplash.com/fr/photos/ZIKnVsJVJpg?utm_source=unsplash&utm_medium=referral&utm_content=creditShareLink

          </code></pre></div>

          
          <hr class="hr-edge-weak">
          </div>
          
        </div>
      </div>
    </div>
  </div>

  <br><br><br>        
  <br><br><br>        
  <br><br><br>  

</section> 


</main>
<!-- End #main -->

<footer id="footer" class="footer">
  <div class="container">
    <div class="projet">
    Projet (PPE) du TAL M1 22/23 réalisé par <strong><span>CUI Xiaohua</span>, </strong><strong><span>Tannina Hamizi</span></strong> et <strong><span>Gemma Felton</span></strong>
    </div>
    <div class="faitpar">
      Dirigés par @<a href="http://www.tal.univ-paris3.fr/plurital/"><strong>pluriTAL</strong></a> | Site basé sur <a href="https://getbootstrap.com/">Bootstrap</a> | <a href="scripts_cn.html#sourceimage">Sources des images du site</a>
      <div class="faitpar">
        <a href="https://github.com/gemmafelton/PPE-group" class="github"><i class="bi bi-github"></i>
      </div>
    </div>
  </div>
</footer>

<script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
<script src="assets/js/main.js"></script>

</body>

</html>


